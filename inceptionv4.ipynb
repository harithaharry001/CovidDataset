{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inceptionv4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7dD2mjN4kqK"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjDWN69-8EOH"
      },
      "source": [
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j9yvwiGB3Nb"
      },
      "source": [
        "class LogisticEndpoint(keras.layers.Layer):\r\n",
        "    def __init__(self, name=None):\r\n",
        "        super(LogisticEndpoint, self).__init__(name=name)\r\n",
        "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\r\n",
        "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\r\n",
        "\r\n",
        "    def call(self, targets, logits, sample_weights=None):\r\n",
        "        # Compute the training-time loss value and add it\r\n",
        "        # to the layer using `self.add_loss()`.\r\n",
        "        loss = self.loss_fn(targets, logits, sample_weights)\r\n",
        "        self.add_loss(loss)\r\n",
        "\r\n",
        "        # Log accuracy as a metric and add it\r\n",
        "        # to the layer using `self.add_metric()`.\r\n",
        "        acc = self.accuracy_fn(targets, logits, sample_weights)\r\n",
        "        self.add_metric(acc, name=\"accuracy\")\r\n",
        "\r\n",
        "        # Return the inference-time prediction tensor (for `.predict()`).\r\n",
        "        return tf.nn.softmax(logits)\r\n",
        "\r\n",
        "layer = LogisticEndpoint()\r\n",
        "\r\n",
        "targets = tf.ones((2, 2))\r\n",
        "logits = tf.ones((2, 2))\r\n",
        "y = layer(targets, logits)\r\n",
        "\r\n",
        "print(\"layer.metrics:\", layer.metrics)\r\n",
        "print(\"current accuracy value:\", float(layer.metrics[0].result()))\r\n",
        "inputs = keras.Input(shape=(3,), name=\"inputs\")\r\n",
        "targets = keras.Input(shape=(10,), name=\"targets\")\r\n",
        "logits = keras.layers.Dense(10)(inputs)\r\n",
        "predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)\r\n",
        "\r\n",
        "model = keras.Model(inputs=[inputs, targets], outputs=predictions)\r\n",
        "model.compile(optimizer=\"adam\")\r\n",
        "\r\n",
        "data = {\r\n",
        "    \"inputs\": np.random.random((3, 3)),\r\n",
        "    \"targets\": np.random.random((3, 10)),\r\n",
        "}\r\n",
        "model.fit(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy-qB8PI4pIQ"
      },
      "source": [
        "from keras.layers import Input\r\n",
        "from keras.layers.merge import concatenate\r\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D\r\n",
        "from keras.layers.convolutional import MaxPooling2D, AveragePooling2D\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2G_0Bug4pFg"
      },
      "source": [
        "def conv_block(x, nb_filter, nb_row, nb_col, padding = \"same\", strides = (1, 1), use_bias = False):\r\n",
        "    '''Defining a Convolution block that will be used throughout the network.'''\r\n",
        "    \r\n",
        "    x = Conv2D(nb_filter, (nb_row, nb_col), strides = strides, padding = padding, use_bias = use_bias)(x)\r\n",
        "    x = BatchNormalization(axis = -1, momentum = 0.9997, scale = False)(x)\r\n",
        "    x = Activation(\"relu\")(x)\r\n",
        "    \r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQef8-xU4xHY"
      },
      "source": [
        "def stem(input):\r\n",
        "    '''The stem of the pure Inception-v4 and Inception-ResNet-v2 networks. This is input part of those networks.'''\r\n",
        "    \r\n",
        "    # Input shape is 299 * 299 * 3 (Tensorflow dimension ordering)\r\n",
        "    x = conv_block(input, 32, 3, 3, strides = (2, 2), padding = \"same\") # 149 * 149 * 32\r\n",
        "    x = conv_block(x, 32, 3, 3, padding = \"same\") # 147 * 147 * 32\r\n",
        "    x = conv_block(x, 64, 3, 3) # 147 * 147 * 64\r\n",
        "\r\n",
        "    x1 = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\")(x)\r\n",
        "    x2 = conv_block(x, 96, 3, 3, strides = (2, 2), padding = \"same\")\r\n",
        "\r\n",
        "    x = concatenate([x1, x2], axis = -1) # 73 * 73 * 160\r\n",
        "\r\n",
        "    x1 = conv_block(x, 64, 1, 1)\r\n",
        "    x1 = conv_block(x1, 96, 3, 3, padding = \"same\")\r\n",
        "\r\n",
        "    x2 = conv_block(x, 64, 1, 1)\r\n",
        "    x2 = conv_block(x2, 64, 1, 7)\r\n",
        "    x2 = conv_block(x2, 64, 7, 1)\r\n",
        "    x2 = conv_block(x2, 96, 3, 3, padding = \"same\")\r\n",
        "\r\n",
        "    x = concatenate([x1, x2], axis = -1) # 71 * 71 * 192\r\n",
        "\r\n",
        "    x1 = conv_block(x, 192, 3, 3, strides = (2, 2), padding = \"same\")\r\n",
        "    \r\n",
        "    x2 = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\")(x)\r\n",
        "\r\n",
        "    x = concatenate([x1, x2], axis = -1) # 35 * 35 * 384\r\n",
        "    \r\n",
        "    return x\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj8RKsur41zd"
      },
      "source": [
        "\r\n",
        "def inception_A(input):\r\n",
        "    '''Architecture of Inception_A block which is a 35 * 35 grid module.'''\r\n",
        "    \r\n",
        "    a1 = AveragePooling2D((3, 3), strides = (1, 1), padding = \"same\")(input)\r\n",
        "    a1 = conv_block(a1, 96, 1, 1)\r\n",
        "    \r\n",
        "    a2 = conv_block(input, 96, 1, 1)\r\n",
        "    \r\n",
        "    a3 = conv_block(input, 64, 1, 1)\r\n",
        "    a3 = conv_block(a3, 96, 3, 3)\r\n",
        "    \r\n",
        "    a4 = conv_block(input, 64, 1, 1)\r\n",
        "    a4 = conv_block(a4, 96, 3, 3)\r\n",
        "    a4 = conv_block(a4, 96, 3, 3)\r\n",
        "    \r\n",
        "    merged = concatenate([a1, a2, a3, a4], axis = -1)\r\n",
        "    \r\n",
        "    return merged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tWoGCDy4585"
      },
      "source": [
        "def inception_B(input):\r\n",
        "    '''Architecture of Inception_B block which is a 17 * 17 grid module.'''\r\n",
        "    \r\n",
        "    b1 = AveragePooling2D((3, 3), strides = (1, 1), padding = \"same\")(input)\r\n",
        "    b1 = conv_block(b1, 128, 1, 1)\r\n",
        "    \r\n",
        "    b2 = conv_block(input, 384, 1, 1)\r\n",
        "    \r\n",
        "    b3 = conv_block(input, 192, 1, 1)\r\n",
        "    b3 = conv_block(b3, 224, 1, 7)\r\n",
        "    b3 = conv_block(b3, 256, 7, 1)\r\n",
        "    \r\n",
        "    b4 = conv_block(input, 192, 1, 1)\r\n",
        "    b4 = conv_block(b4, 192, 7, 1)\r\n",
        "    b4 = conv_block(b4, 224, 1, 7)\r\n",
        "    b4 = conv_block(b4, 224, 7, 1)\r\n",
        "    b4 = conv_block(b4, 256, 1, 7)\r\n",
        "    \r\n",
        "    merged = concatenate([b1, b2, b3, b4], axis = -1)\r\n",
        "    \r\n",
        "    return merged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAZWz7HP48sp"
      },
      "source": [
        "def inception_C(input):\r\n",
        "    '''Architecture of Inception_C block which is a 8 * 8 grid module.'''\r\n",
        "    \r\n",
        "    c1 = AveragePooling2D((3, 3), strides = (1, 1), padding = \"same\")(input)\r\n",
        "    c1 = conv_block(c1, 256, 1, 1)\r\n",
        "    \r\n",
        "    c2 = conv_block(input, 256, 1, 1)\r\n",
        "\r\n",
        "    c3 = conv_block(input, 384, 1, 1)\r\n",
        "    c31 = conv_block(c2, 256, 1, 3)\r\n",
        "    c32 = conv_block(c2, 256, 3, 1)\r\n",
        "    c3 = concatenate([c31, c32], axis = -1)\r\n",
        "\r\n",
        "    c4 = conv_block(input, 384, 1, 1)\r\n",
        "    c4 = conv_block(c3, 448, 3, 1)\r\n",
        "    c4 = conv_block(c3, 512, 1, 3)\r\n",
        "    c41 = conv_block(c3, 256, 1, 3)\r\n",
        "    c42 = conv_block(c3, 256, 3, 1)\r\n",
        "    c4 = concatenate([c41, c42], axis = -1)\r\n",
        "  \r\n",
        "    merged = concatenate([c1, c2, c3, c4], axis = -1)\r\n",
        "    \r\n",
        "    return merged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCv_ICWM4_29"
      },
      "source": [
        "def reduction_A(input, k = 192, l = 224, m = 256, n = 384):\r\n",
        "    '''Architecture of a 35 * 35 to 17 * 17 Reduction_A block.'''\r\n",
        "\r\n",
        "    ra1 = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\")(input)\r\n",
        "    \r\n",
        "    ra2 = conv_block(input, n, 3, 3, strides = (2, 2), padding = \"same\")\r\n",
        "\r\n",
        "    ra3 = conv_block(input, k, 1, 1)\r\n",
        "    ra3 = conv_block(ra3, l, 3, 3)\r\n",
        "    ra3 = conv_block(ra3, m, 3, 3, strides = (2, 2), padding = \"same\")\r\n",
        "\r\n",
        "    merged = concatenate([ra1, ra2, ra3], axis = -1)\r\n",
        "    \r\n",
        "    return merged\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C8ki8yI5Cu-"
      },
      "source": [
        "def reduction_B(input):\r\n",
        "    '''Architecture of a 17 * 17 to 8 * 8 Reduction_B block.'''\r\n",
        "    \r\n",
        "    rb1 = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\")(input)\r\n",
        "    \r\n",
        "    rb2 = conv_block(input, 192, 1, 1)\r\n",
        "    rb2 = conv_block(rb2, 192, 3, 3, strides = (2, 2), padding = \"same\")\r\n",
        "    \r\n",
        "    rb3 = conv_block(input, 256, 1, 1)\r\n",
        "    rb3 = conv_block(rb3, 256, 1, 7)\r\n",
        "    rb3 = conv_block(rb3, 320, 7, 1)\r\n",
        "    rb3 = conv_block(rb3, 320, 3, 3, strides = (2, 2), padding = \"same\")\r\n",
        "    \r\n",
        "    merged = concatenate([rb1, rb2, rb3], axis = -1)\r\n",
        "    \r\n",
        "    return merged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpl40ezH5GCu"
      },
      "source": [
        "def inception_v4(nb_classes = 2, load_weights = True):\r\n",
        "    '''Creates the Inception_v4 network.'''\r\n",
        "    \r\n",
        "    init = Input((299, 299, 3)) # Channels last, as using Tensorflow backend with Tensorflow image dimension ordering\r\n",
        "    \r\n",
        "    # Input shape is 299 * 299 * 3\r\n",
        "    x = stem(init) # Output: 35 * 35 * 384\r\n",
        "    \r\n",
        "    # 4 x Inception A\r\n",
        "    for i in range(4):\r\n",
        "        x = inception_A(x)\r\n",
        "        # Output: 35 * 35 * 384\r\n",
        "        \r\n",
        "    # Reduction A\r\n",
        "    x = reduction_A(x, k = 192, l = 224, m = 256, n = 384) # Output: 17 * 17 * 1024\r\n",
        "\r\n",
        "    # 7 x Inception B\r\n",
        "    for i in range(7):\r\n",
        "        x = inception_B(x)\r\n",
        "        # Output: 17 * 17 * 1024\r\n",
        "        \r\n",
        "    # Reduction B\r\n",
        "    x = reduction_B(x) # Output: 8 * 8 * 1536\r\n",
        "\r\n",
        "    # 3 x Inception C\r\n",
        "    for i in range(3):\r\n",
        "        x = inception_C(x) \r\n",
        "        # Output: 8 * 8 * 1536\r\n",
        "        \r\n",
        "    # Average Pooling\r\n",
        "    x = AveragePooling2D((8, 8))(x) # Output: 1536\r\n",
        "\r\n",
        "    # Dropout\r\n",
        "    x = Dropout(0.2)(x) # Keep dropout 0.2 as mentioned in the paper\r\n",
        "    x = Flatten()(x) # Output: 1536\r\n",
        "\r\n",
        "    # Output layer\r\n",
        "    output = Dense(units = nb_classes, activation = \"softmax\")(x) # Output: 1000\r\n",
        "\r\n",
        "    model = Model(init, output, name = \"Inception-v4\")   \r\n",
        "        \r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC5SUf3y5JOP"
      },
      "source": [
        "if __name__ == \"__main__\":\r\n",
        "    inception_v4 = inception_v4()\r\n",
        "    inception_v4.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpsVP158BtSg"
      },
      "source": [
        "inception_v4.compile(\r\n",
        "loss=keras.losses.binary_crossentropy,optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp6XHjyqBqKj"
      },
      "source": [
        "from os import listdir\r\n",
        "from matplotlib import image\r\n",
        "from skimage.transform import resize\r\n",
        "\r\n",
        "def load_data(path): \r\n",
        "    train_files = []\r\n",
        "    for foldername1 in listdir(path):\r\n",
        "        filepath1 = path  + \"/\" + foldername1\r\n",
        "        for filename1 in listdir(filepath1):\r\n",
        "            train_files.append(filepath1 + \"/\" + filename1)\r\n",
        "            \r\n",
        "    # Original Dimensions\r\n",
        "    image_width = 299\r\n",
        "    image_height = 299\r\n",
        "    channels = 3\r\n",
        "    \r\n",
        "    loaded_images = np.ndarray(shape=(len(train_files), image_height, image_width, channels),dtype=np.float32)\r\n",
        "    print(type(loaded_images))\r\n",
        "    loaded_class = []\r\n",
        "    i = 0\r\n",
        "    for foldername in listdir(path):\r\n",
        "        filepath = path  + \"/\" + foldername\r\n",
        "        print(\"Folder : \",filepath)\r\n",
        "        for filename in listdir(filepath):\r\n",
        "            # load image\r\n",
        "            img_data = image.imread(filepath + \"/\" + filename)\r\n",
        "            \r\n",
        "            # store loaded image\r\n",
        "            img_data = resize(img_data, (299, 299, 3))\r\n",
        "            loaded_images[i] = img_data\r\n",
        "            loaded_class.append(foldername)\r\n",
        "            i = i + 1\r\n",
        "            #print('> loaded %s %s' % (filename, img_data.shape))\r\n",
        "        print('Loaded: ',i , ' images from ',filepath)\r\n",
        "            \r\n",
        "    return loaded_images,loaded_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2M0VpgkCH1T",
        "outputId": "e86af2f0-fcf9-49ed-d4ee-02a518c1718e"
      },
      "source": [
        "path = r\"/content/drive/MyDrive/Colab Notebooks/Project\"\r\n",
        "x,y = load_data(path)\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "Folder :  /content/drive/MyDrive/Colab Notebooks/Project/Covid\n",
            "Loaded:  563  images from  /content/drive/MyDrive/Colab Notebooks/Project/Covid\n",
            "Folder :  /content/drive/MyDrive/Colab Notebooks/Project/Normal\n",
            "Loaded:  929  images from  /content/drive/MyDrive/Colab Notebooks/Project/Normal\n",
            "Folder :  /content/drive/MyDrive/Colab Notebooks/Project/.ipynb_checkpoints\n",
            "Loaded:  929  images from  /content/drive/MyDrive/Colab Notebooks/Project/.ipynb_checkpoints\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B5IQqTlCYss"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkwH2PC4CazB",
        "outputId": "fe61e879-43f8-43a2-9bac-8bb19fcb9241"
      },
      "source": [
        "print(train_x.shape)\r\n",
        "print(test_x.shape)\r\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(650, 299, 299, 3)\n",
            "(279, 299, 299, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF07X83lCqFK",
        "outputId": "ffa0bcab-3470-4ce4-e439-cc348f6740df"
      },
      "source": [
        "from keras.utils import to_categorical\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "y_train_values, unique = pd.factorize(train_y)\r\n",
        "print('y_train ', y_train_values, unique)\r\n",
        "\r\n",
        "\r\n",
        "y_test_values, unique = pd.factorize(test_y)\r\n",
        "print('y_test ', y_test_values, unique)\r\n",
        "\r\n",
        "y_train_one_hot = to_categorical(y_train_values)\r\n",
        "y_test_one_hot = to_categorical(y_test_values)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train  [0 1 0 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0\n",
            " 0 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 0 1 1 0 1 0\n",
            " 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1\n",
            " 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1\n",
            " 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1\n",
            " 1 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1\n",
            " 0 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1\n",
            " 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1\n",
            " 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1\n",
            " 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1] ['Normal' 'Covid']\n",
            "y_test  [0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0\n",
            " 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1\n",
            " 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0\n",
            " 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1\n",
            " 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0\n",
            " 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1\n",
            " 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 0] ['Covid' 'Normal']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki7Tvvu9Cr3S"
      },
      "source": [
        "x_train_normalization = train_x / 255.0\r\n",
        "x_test_normalization = test_x / 255.0"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb2RIoqMCu8E"
      },
      "source": [
        "from sklearn.utils import shuffle\r\n",
        "\r\n",
        "\r\n",
        "x_shuffled_default, y_shuffled_default = shuffle(x_train_normalization, y_train_one_hot)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pCqrEFNCxbG",
        "outputId": "98d06e4f-da05-4c0b-d9b4-c3732ebbe876"
      },
      "source": [
        " inception_v4.fit(x_shuffled_default, y_shuffled_default, batch_size=256, epochs=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}