{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMduWrJbmV8nU92E0PU92CT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harithaharry001/CovidDataset/blob/master/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBDLV7lgsxvv",
        "outputId": "34634673-80c4-4733-8db5-173de0a18c18"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrVrHUmitAkc"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv2D, Dropout, MaxPooling2D, BatchNormalization, Activation, Flatten, Dense\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyJKqfMCtMKp"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import numpy as np\r\n",
        "from os import listdir\r\n",
        "from matplotlib import image\r\n",
        "from skimage.transform import resize\r\n",
        "\r\n",
        "\r\n",
        "def load_data(path):\r\n",
        "    \r\n",
        "    train_files = []\r\n",
        "    for foldername1 in listdir(path):\r\n",
        "        filepath1 = path  + \"/\" + foldername1\r\n",
        "        for filename1 in listdir(filepath1):\r\n",
        "            train_files.append(filepath1 + \"/\" + filename1)\r\n",
        "            \r\n",
        "    # Original Dimensions\r\n",
        "    image_width = 224\r\n",
        "    image_height = 224\r\n",
        "    channels = 3\r\n",
        "    \r\n",
        "    loaded_images = np.ndarray(shape=(len(train_files), image_height, image_width, channels),dtype=np.float32)\r\n",
        "    print(type(loaded_images))\r\n",
        "    loaded_class = []\r\n",
        "    i = 0\r\n",
        "    for foldername in listdir(path):\r\n",
        "        filepath = path  + \"/\" + foldername\r\n",
        "        print(\"Folder : \",filepath)\r\n",
        "        for filename in listdir(filepath):\r\n",
        "            # load image\r\n",
        "            img_data = image.imread(filepath + \"/\" + filename)\r\n",
        "            \r\n",
        "            # store loaded image\r\n",
        "            img_data = resize(img_data, (224, 224, 3))\r\n",
        "            loaded_images[i] = img_data\r\n",
        "            loaded_class.append(foldername)\r\n",
        "            i = i + 1\r\n",
        "            #print('> loaded %s %s' % (filename, img_data.shape))\r\n",
        "        print('Loaded: ',i , ' images from ',filepath)\r\n",
        "            \r\n",
        "    return loaded_images,loaded_class\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJCTLcuitXnp",
        "outputId": "97172f19-6730-4b1c-d3ee-0cfd5112527f"
      },
      "source": [
        "path = r\"/content/drive/MyDrive/Dataset\"\r\n",
        "x,y = load_data(path)\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "Folder :  /content/drive/MyDrive/Dataset/Covid\n",
            "Loaded:  478  images from  /content/drive/MyDrive/Dataset/Covid\n",
            "Folder :  /content/drive/MyDrive/Dataset/Normal\n",
            "Loaded:  2358  images from  /content/drive/MyDrive/Dataset/Normal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqgTFZ6LtaEL",
        "outputId": "f399055c-f058-4c41-d0e6-918f9db65db7"
      },
      "source": [
        "print(train_x.shape)\r\n",
        "print(test_x.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1650, 224, 224, 3)\n",
            "(708, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cez5NDKwth93",
        "outputId": "2959b2ad-f2b2-4bf6-b44e-79fb89d717d9"
      },
      "source": [
        "# Creating a Sequential model\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# 1st Convolution Layer\r\n",
        "model.add(Conv2D(filters=96, kernel_size=(11,11), input_shape=(224, 224, 3), strides=(4,4), padding='valid'))\r\n",
        "# Normalization\r\n",
        "model.add(BatchNormalization())\r\n",
        "# Activation Function\r\n",
        "model.add(Activation('relu'))\r\n",
        "# Max-Pooling\r\n",
        "model.add(MaxPooling2D((3,3), strides=(2,2), padding='valid'))\r\n",
        "\r\n",
        "\r\n",
        "# 2nd Convolution Layer\r\n",
        "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\r\n",
        "# Normalization\r\n",
        "model.add(BatchNormalization())\r\n",
        "# Activation Function\r\n",
        "model.add(Activation('relu'))\r\n",
        "# Max-Pooling\r\n",
        "model.add(MaxPooling2D((3,3), strides=(2,2), padding='valid'))\r\n",
        "\r\n",
        "\r\n",
        "# 3rd Convolution Layer\r\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), padding='same'))\r\n",
        "# Normalization\r\n",
        "model.add(BatchNormalization())\r\n",
        "# Activation Function\r\n",
        "model.add(Activation('relu'))\r\n",
        "\r\n",
        "\r\n",
        "# 4th Convolution Layer\r\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), padding='same'))\r\n",
        "# Normalization\r\n",
        "model.add(BatchNormalization())\r\n",
        "# Activation Function\r\n",
        "model.add(Activation('relu'))\r\n",
        "\r\n",
        "\r\n",
        "# 5th Convolution Layer\r\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\r\n",
        "# Normalization\r\n",
        "model.add(BatchNormalization())\r\n",
        "# Activation Function\r\n",
        "model.add(Activation('relu'))\r\n",
        "# Max-Pooling\r\n",
        "model.add(MaxPooling2D((3,3), strides=(2,2), padding='valid'))\r\n",
        "\r\n",
        "\r\n",
        "# Flattening before passing to the Dense layer\r\n",
        "model.add(Flatten())\r\n",
        "\r\n",
        "\r\n",
        "# 1st Dense Layer\r\n",
        "model.add(Dense(4096))\r\n",
        "# Dropout\r\n",
        "model.add(Dropout(0.4))\r\n",
        "# Normalization\r\n",
        "model.add(BatchNormalization())\r\n",
        "# Activation Function\r\n",
        "model.add(Activation('relu'))\r\n",
        "\r\n",
        "\r\n",
        "# 2nd Dense Layer\r\n",
        "model.add(Dense(4096))\r\n",
        "# Dropout\r\n",
        "model.add(Dropout(0.4))\r\n",
        "# Normalization\r\n",
        "model.add(BatchNormalization())\r\n",
        "# Activation Function\r\n",
        "model.add(Activation('relu'))\r\n",
        "\r\n",
        "\r\n",
        "# Output softmax Layer\r\n",
        "model.add(Dense(2))\r\n",
        "# Activation Function\r\n",
        "model.add(Activation('softmax'))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 54, 54, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 26, 26, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 26, 26, 256)       614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 26, 26, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 26, 26, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 12, 12, 384)       885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 12, 12, 384)       1536      \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 12, 12, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 12, 12, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 12, 12, 384)       1536      \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 12, 12, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 12, 12, 256)       884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4096)              26218496  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 8194      \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 46,793,474\n",
            "Trainable params: 46,774,338\n",
            "Non-trainable params: 19,136\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6FeUxLRtrsE",
        "outputId": "b2896b91-ddc7-4048-c7f0-eef3a9111d8d"
      },
      "source": [
        "import pandas as pd\r\n",
        "from keras.utils import to_categorical\r\n",
        "y_train_values, unique = pd.factorize(train_y)\r\n",
        "print('y_train ', y_train_values, unique)\r\n",
        "\r\n",
        "\r\n",
        "y_test_values, unique = pd.factorize(test_y)\r\n",
        "print('y_test ', y_test_values, unique)\r\n",
        "\r\n",
        "y_train_one_hot = to_categorical(y_train_values)\r\n",
        "y_test_one_hot = to_categorical(y_test_values)\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train  [0 0 0 ... 0 1 0] ['Normal' 'Covid']\n",
            "y_test  [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1\n",
            " 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
            " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
            " 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
            " 0 1 0 1 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
            " 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
            " 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 1 1] ['Normal' 'Covid']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ne-UlJOtvq1"
      },
      "source": [
        "x_train_normalization = train_x / 255.0\r\n",
        "x_test_normalization = test_x / 255.0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6_yWXKEty5s"
      },
      "source": [
        "from sklearn.utils import shuffle\r\n",
        "\r\n",
        "\r\n",
        "x_shuffled_default, y_shuffled_default = shuffle(x_train_normalization, y_train_one_hot)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN3FAryetz04"
      },
      "source": [
        "model.compile(\r\n",
        "loss=keras.losses.binary_crossentropy,optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKLQfxtet5Pt"
      },
      "source": [
        "model.fit(x_shuffled_default, y_shuffled_default, epochs = 30, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}